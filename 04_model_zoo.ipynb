{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate over classifiers with Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fastcore.test import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from Yikai_helper_funcs import * \n",
    "from sklearn.datasets import make_classification\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_multilabel_classification, make_regression\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from fastai.data.transforms import get_files\n",
    "from pathlib import Path\n",
    "\n",
    "# from fastcore.basics import store_attr  # has bugs currently\n",
    "\n",
    "from Yikai_helper_funcs.params import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"Synthetic binary classification dataset.\"\"\"\n",
    "    data, targets = make_classification(\n",
    "        n_samples=100,\n",
    "        n_features=45)\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "x, y = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def _compile_results(root_dir):\n",
    "    \n",
    "    '''\n",
    "    This is the function to conpile results from different models that are stored in a root dirctory.\n",
    "    Results were stored in .json file where each .json file corresponds to one call of an optinizer.\n",
    "    \n",
    "    Params:\n",
    "        root_dir (str or Path ): The root directory where all the .json files were stored\n",
    "    '''\n",
    "    if len(get_files(root_dir, extensions= \".json\")) == 1: \n",
    "        file = get_files(root_dir, extensions= \".json\")[0]\n",
    "        model_name = str(Path(file).parent).split(\"/\")[-1]\n",
    "        df_init = pd.read_json(file, lines=True)\n",
    "        df_init['model'] = [model_name] * df_init.shape[0]\n",
    "        return df_init\n",
    "    \n",
    "    else:\n",
    "        for i, file in enumerate(get_files(root_dir, extensions= \".json\")):\n",
    "            #print(file)\n",
    "            model_name = str(Path(file).parent).split(\"/\")[-1]\n",
    "            #print(model_name)\n",
    "            if not i:\n",
    "                df_init = pd.read_json(file, lines=True)\n",
    "                df_init['model'] = [model_name] * df_init.shape[0]\n",
    "            else: \n",
    "                df = pd.read_json(file, lines=True)\n",
    "                df['model'] = [model_name] * df.shape[0]\n",
    "                df_final = pd.concat([df_init, df], ignore_index = True).sort_values('target', ascending= False)\n",
    "\n",
    "        return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path('./bayes_opt_logs/').exists():\n",
    "    df = _compile_results(Path('./bayes_opt_logs/')) # './bayes_opt_logs/' works fine as well.\n",
    "    df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ModelIterator:\n",
    "    \n",
    "    def __init__(self, x, y, *, rf_params = None, xgboost_params = None, \n",
    "                 lightgbm_params = None, log_path = Path(\"./bayes_opt_logs\"),\n",
    "                rf_init_points = 10, rf_n_iter = 5,\n",
    "                xgboost_init_points = 10, xgboost_n_iter = 5, \n",
    "                lightgbm_init_points = 10, lightgbm_n_iter = 5):\n",
    "    \n",
    "\n",
    "        self.log_path = Path(log_path)\n",
    "        if not rf_params: self.rf_params = {}\n",
    "        if not lightgbm_params: self.lightgbm_params = {}\n",
    "        if not xgboost_params: self.xgboost_params = {} # These are passed in the fit_predict method\n",
    "        self.rf_init_points = rf_init_points\n",
    "        self.rf_n_iter = rf_n_iter\n",
    "        self.xgboost_init_points = xgboost_init_points\n",
    "        self.xgboost_n_iter = xgboost_n_iter\n",
    "        self.lightgbm_init_points = lightgbm_init_points\n",
    "        self.lightgbm_n_iter = lightgbm_n_iter\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    \n",
    "    # TODO: Change hardcoded init_points & n_iter\n",
    "    # TODO: Add try except blocks\n",
    "    def _run_rf(self, x, y, **kwargs_model ):\n",
    "        \"\"\"  run RF and log tehm at self.log_path\n",
    "        \n",
    "        Params:\n",
    "            kwargs_model: the range for hyperparameters that you want to overwrite the default generated from \n",
    "                        RFParamGenerator().matrix_generation()\n",
    "                        \n",
    "        \"\"\" \n",
    "        params_forest = RFParamGenerator(**kwargs_model).matrix_generation()\n",
    "        @optimize_bayes_param(X=x, y=y)\n",
    "        def optimize_forest(n_estimators, min_samples_split, max_depth , ccp_alpha):\n",
    "            return RandomForestClassifier(n_estimators=int(n_estimators), min_samples_split=int(min_samples_split),  \n",
    "                                          max_depth = int(max_depth), ccp_alpha = float(ccp_alpha), n_jobs=-1) \n",
    "        best_rf = optimize_forest(init_points=self.rf_init_points, n_iter=self.rf_n_iter, pbounds=params_forest, log_dir= self.log_path/\"forest\")\n",
    "        return best_rf\n",
    "    \n",
    "    \n",
    "    def _run_xgboost(self, x, y, **kwargs_model ):\n",
    "        \"\"\"  run Xgboost and log tehm at self.log_path\n",
    "        \n",
    "        Params:\n",
    "            kwargs_model: the range for hyperparameters that you want to overwrite the default generated from \n",
    "                        XgboostParamGenerator().matrix_generation()\n",
    "                        \n",
    "        \"\"\" \n",
    "        params_xgboost = XgboostParamGenerator(**kwargs_model).matrix_generation()\n",
    "\n",
    "        @optimize_bayes_param(X=x, y=y)\n",
    "        def optimize_xgboost(n_estimators, max_depth, min_child_weight, gamma,learning_rate, subsample):\n",
    "            return XGBClassifier(n_estimators= int(n_estimators), max_depth = int(max_depth), \n",
    "            min_child_weight = min_child_weight , gamma = gamma, learning_rate = learning_rate,\n",
    "            subsample = subsample,\n",
    "            n_jobs=-1)\n",
    "\n",
    "        best_xgboost = optimize_xgboost(init_points=self.xgboost_init_points, n_iter=self.xgboost_n_iter, pbounds=params_xgboost, log_dir=self.log_path/\"xgboost\")\n",
    "        return best_xgboost\n",
    "    \n",
    "    def _run_lightgbm(self, x, y, **kwargs_model):\n",
    "            \n",
    "        \"\"\"  run Lightgbm and log tehm at self.log_path\n",
    "        \n",
    "        Params:\n",
    "            kwargs_model: the range for hyperparameters that you want to overwrite the default generated from \n",
    "                        LgbmParamGenerator().matrix_generation()\n",
    "            \"\"\"\n",
    "\n",
    "        params_lgbm = LgbmParamGenerator(**kwargs_model).matrix_generation()\n",
    "\n",
    "        @optimize_bayes_param(X=x, y=y)\n",
    "        def optimize_lgbm(num_leaves: int,learning_rate:float, min_child_samples, reg_alpha, reg_lambda, colsample_bytree):\n",
    "            return LGBMClassifier(  \n",
    "                **{\n",
    "                \"num_leaves\" : int(num_leaves),\n",
    "                \"learning_rate\" : float(learning_rate),\n",
    "               \"min_child_samples\" : int(min_child_samples),\n",
    "                \"reg_alpha\" : float(reg_alpha),\n",
    "                \"reg_lambda\" : float(reg_lambda),\n",
    "               'colsample_bytree': float(colsample_bytree)   \n",
    "            })\n",
    "\n",
    "        best_lightgbm = optimize_lgbm(init_points=5, n_iter=10, pbounds= params_lgbm, log_dir= self.log_path/\"lgbm\")\n",
    "        return best_lightgbm\n",
    "    \n",
    "    def fit_predict(self, compile_results = True):\n",
    "        \n",
    "        best_rf = self._run_rf(self.x, self.y, **self.rf_params)\n",
    "        best_xgboost = self._run_xgboost(self.x, self.y, **self.xgboost_params)\n",
    "       # best_lightgbm = self._run_lightgbm(x, y, **self.lightgbm_params)\n",
    "        \n",
    "        print(\"\"\"\n",
    "        ----------------------------------------------------\n",
    "        Returned best_rf, best_xgboost\n",
    "        \n",
    "        \"\"\")\n",
    "        return best_rf, best_xgboost #, best_lightgbm\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.fit_predict()\n",
    "    \n",
    "    def compile_results(self):\n",
    "        return _compile_results(self.log_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = ModelIterator(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best combination of hyperparameters are {'ccp_alpha': 0.029834902375002192, 'max_depth': 35.69860577029296, 'min_samples_split': 4.497178477874517, 'n_estimators': 406.4077438886299}\n",
      "The best score for the hyperparameters are 0.99\n",
      "The best combination of hyperparameters are {'gamma': 10.457964153104308, 'learning_rate': 0.27079083302557405, 'max_depth': 3.9195331071476, 'min_child_weight': 0.22851186079028146, 'n_estimators': 97.85382371807863, 'subsample': 0.5507585185908407}\n",
      "The best score for the hyperparameters are 0.99\n",
      "\n",
      "        ----------------------------------------------------\n",
      "        Returned best_rf, best_xgboost\n",
      "        \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "a,b = iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert a.__class__.__name__ == \"RandomForestClassifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>params</th>\n      <th>datetime</th>\n      <th>model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.99</td>\n      <td>{'ccp_alpha': 0.029834902375002, 'max_depth': 35.69860577029296, 'min_samples_split': 4.497178477874517, 'n_estimators': 406.4077438886299}</td>\n      <td>{'datetime': '2020-10-30 12:15:31', 'elapsed': 0.0, 'delta': 0.0}</td>\n      <td>forest</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.99</td>\n      <td>{'ccp_alpha': 0.049457167892975, 'max_depth': 21.34714460344915, 'min_samples_split': 2.097431305959691, 'n_estimators': 489.86987505735203}</td>\n      <td>{'datetime': '2020-10-30 12:15:45', 'elapsed': 14.030575, 'delta': 2.085842}</td>\n      <td>forest</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.99</td>\n      <td>{'ccp_alpha': 0.021861492413113002, 'max_depth': 83.05304497803968, 'min_samples_split': 20.243912858025652, 'n_estimators': 270.7014108189465}</td>\n      <td>{'datetime': '2020-10-30 12:15:33', 'elapsed': 2.019139, 'delta': 0.823596}</td>\n      <td>forest</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.99</td>\n      <td>{'ccp_alpha': 0.043781538376893005, 'max_depth': 62.67572775871829, 'min_samples_split': 46.88187614036777, 'n_estimators': 358.8362393777668}</td>\n      <td>{'datetime': '2020-10-30 12:15:35', 'elapsed': 4.171425, 'delta': 1.260813}</td>\n      <td>forest</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.99</td>\n      <td>{'ccp_alpha': 0.01, 'max_depth': 44.14258634567429, 'min_samples_split': 2.0, 'n_estimators': 360.63113095974927}</td>\n      <td>{'datetime': '2020-10-30 12:15:40', 'elapsed': 8.294351, 'delta': 1.25263}</td>\n      <td>forest</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.99</td>\n      <td>{'ccp_alpha': 0.1, 'max_depth': 105.0, 'min_samples_split': 25.40894051245977, 'n_estimators': 158.47752924077685}</td>\n      <td>{'datetime': '2020-10-30 12:15:40', 'elapsed': 9.178861, 'delta': 0.88451}</td>\n      <td>forest</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.99</td>\n      <td>{'ccp_alpha': 0.069757657642516, 'max_depth': 75.70271526835617, 'min_samples_split': 2.0, 'n_estimators': 389.6688850547288}</td>\n      <td>{'datetime': '2020-10-30 12:15:42', 'elapsed': 10.656779, 'delta': 1.4779179999999998}</td>\n      <td>forest</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.99</td>\n      <td>{'ccp_alpha': 0.1, 'max_depth': 105.0, 'min_samples_split': 2.0, 'n_estimators': 247.90684002652753}</td>\n      <td>{'datetime': '2020-10-30 12:15:43', 'elapsed': 11.944733, 'delta': 1.287954}</td>\n      <td>forest</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.89</td>\n      <td>{'gamma': 5.7300257335118445, 'learning_rate': 0.22360059477888103, 'max_depth': 3.8748947524170463, 'min_child_weight': 0.341132165498487, 'n_estimators': 86.43925887285536, 'subsample': 0.499383142077564}</td>\n      <td>{'datetime': '2020-10-30 12:14:42', 'elapsed': 1.201651, 'delta': 0.12539799999999998}</td>\n      <td>xgboost</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.89</td>\n      <td>{'ccp_alpha': 0.090029399554787, 'max_depth': 89.50191040914383, 'min_samples_split': 54.93897219851763, 'n_estimators': 160.88551700701495}</td>\n      <td>{'datetime': '2020-10-30 12:15:38', 'elapsed': 7.041721, 'delta': 0.594742}</td>\n      <td>forest</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.88</td>\n      <td>{'gamma': 21.120544444663825, 'learning_rate': 0.22791705648514501, 'max_depth': 4.042679275107872, 'min_child_weight': 0.295275762314321, 'n_estimators': 58.5552736817226, 'subsample': 0.314009255628853}</td>\n      <td>{'datetime': '2020-10-30 12:14:43', 'elapsed': 1.287337, 'delta': 0.085686}</td>\n      <td>xgboost</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.87</td>\n      <td>{'gamma': 16.44338760251217, 'learning_rate': 0.05256451789020201, 'max_depth': 10.204316877141467, 'min_child_weight': 0.37087034414053205, 'n_estimators': 46.822120065426, 'subsample': 0.9300408535358081}</td>\n      <td>{'datetime': '2020-10-30 12:14:42', 'elapsed': 0.708824, 'delta': 0.078763}</td>\n      <td>xgboost</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.87</td>\n      <td>{'gamma': 5.438404255901645, 'learning_rate': 0.09912926135240001, 'max_depth': 10.875423657001221, 'min_child_weight': 0.29817664781213604, 'n_estimators': 16.20797044801588, 'subsample': 0.427833352953212}</td>\n      <td>{'datetime': '2020-10-30 12:14:42', 'elapsed': 0.489853, 'delta': 0.029512999999999998}</td>\n      <td>xgboost</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.87</td>\n      <td>{'gamma': 23.902685646619545, 'learning_rate': 0.140220199304396, 'max_depth': 10.427755231286966, 'min_child_weight': 0.190043303481046, 'n_estimators': 78.53806058006883, 'subsample': 0.9309827198629641}</td>\n      <td>{'datetime': '2020-10-30 12:14:41', 'elapsed': 0.269099, 'delta': 0.14562899999999998}</td>\n      <td>xgboost</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.87</td>\n      <td>{'gamma': 8.242909356404795, 'learning_rate': 0.16402715204211002, 'max_depth': 4.102014314175854, 'min_child_weight': 0.254792568787706, 'n_estimators': 81.02980474091669, 'subsample': 0.582389761305676}</td>\n      <td>{'datetime': '2020-10-30 12:14:43', 'elapsed': 1.418638, 'delta': 0.131301}</td>\n      <td>xgboost</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.85</td>\n      <td>{'gamma': 12.065206351393131, 'learning_rate': 0.237563668878209, 'max_depth': 10.40085688904697, 'min_child_weight': 0.45836193440548206, 'n_estimators': 64.7779454870973, 'subsample': 0.690572316508353}</td>\n      <td>{'datetime': '2020-10-30 12:14:42', 'elapsed': 0.46034, 'delta': 0.09467}</td>\n      <td>xgboost</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.85</td>\n      <td>{'gamma': 26.845075131722044, 'learning_rate': 0.05637995945751, 'max_depth': 5.2311147200267865, 'min_child_weight': 0.38931716803493505, 'n_estimators': 99.60686866353187, 'subsample': 0.668658337550876}</td>\n      <td>{'datetime': '2020-10-30 12:14:42', 'elapsed': 0.630061, 'delta': 0.140208}</td>\n      <td>xgboost</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.85</td>\n      <td>{'gamma': 29.098063156312993, 'learning_rate': 0.132438457038936, 'max_depth': 6.760558963353372, 'min_child_weight': 0.20321910481126101, 'n_estimators': 89.52767108203464, 'subsample': 0.9907861999654861}</td>\n      <td>{'datetime': '2020-10-30 12:14:42', 'elapsed': 0.866756, 'delta': 0.157932}</td>\n      <td>xgboost</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.85</td>\n      <td>{'gamma': 35.40752339424799, 'learning_rate': 0.11638576576879502, 'max_depth': 11.946226616391376, 'min_child_weight': 0.21271170406467202, 'n_estimators': 22.473116195253535, 'subsample': 0.941746701654088}</td>\n      <td>{'datetime': '2020-10-30 12:14:42', 'elapsed': 0.9163319999999999, 'delta': 0.049575999999999995}</td>\n      <td>xgboost</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.84</td>\n      <td>{'gamma': 12.008139725538545, 'learning_rate': 0.190519070111762, 'max_depth': 10.277996345197241, 'min_child_weight': 0.10229010266377, 'n_estimators': 64.2924671568606, 'subsample': 0.32337358470530403}</td>\n      <td>{'datetime': '2020-10-30 12:14:42', 'elapsed': 1.076253, 'delta': 0.089782}</td>\n      <td>xgboost</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.82</td>\n      <td>{'gamma': 21.349653589083115, 'learning_rate': 0.21358292424761802, 'max_depth': 9.566140475222866, 'min_child_weight': 0.528480038845596, 'n_estimators': 94.42886299055723, 'subsample': 0.391226481412892}</td>\n      <td>{'datetime': '2020-10-30 12:14:41', 'elapsed': 0.12347000000000001, 'delta': 0.12347000000000001}</td>\n      <td>xgboost</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.82</td>\n      <td>{'gamma': 28.70720798082302, 'learning_rate': 0.252551849877212, 'max_depth': 6.481601351187299, 'min_child_weight': 0.5701211390530441, 'n_estimators': 86.78484184655254, 'subsample': 0.44040453871295304}</td>\n      <td>{'datetime': '2020-10-30 12:14:42', 'elapsed': 0.36567000000000005, 'delta': 0.09657099999999999}</td>\n      <td>xgboost</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.57</td>\n      <td>{'gamma': 38.070990054984044, 'learning_rate': 0.28076336388418605, 'max_depth': 9.327504220779613, 'min_child_weight': 0.5628833420567271, 'n_estimators': 22.270791810081622, 'subsample': 0.604910459818371}</td>\n      <td>{'datetime': '2020-10-30 12:14:42', 'elapsed': 0.986471, 'delta': 0.07013899999999999}</td>\n      <td>xgboost</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.51</td>\n      <td>{'ccp_alpha': 0.040246899179255, 'max_depth': 49.92967821882293, 'min_samples_split': 57.113265209214546, 'n_estimators': 420.89718548783173}</td>\n      <td>{'datetime': '2020-10-30 12:15:38', 'elapsed': 6.446979, 'delta': 1.372838}</td>\n      <td>forest</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.51</td>\n      <td>{'ccp_alpha': 0.057339702313048004, 'max_depth': 25.554099877521686, 'min_samples_split': 69.38910049608978, 'n_estimators': 241.34776350907418}</td>\n      <td>{'datetime': '2020-10-30 12:15:36', 'elapsed': 5.074141, 'delta': 0.902716}</td>\n      <td>forest</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.51</td>\n      <td>{'ccp_alpha': 0.010163693535097001, 'max_depth': 75.53338720453232, 'min_samples_split': 85.32894324650903, 'n_estimators': 106.00648636175973}</td>\n      <td>{'datetime': '2020-10-30 12:15:32', 'elapsed': 0.58179, 'delta': 0.41872499999999996}</td>\n      <td>forest</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.50</td>\n      <td>{'gamma': 18.63749998555996, 'learning_rate': 0.13918876224437302, 'max_depth': 4.452858224882912, 'min_child_weight': 0.134993520008951, 'n_estimators': 55.72801664920143, 'subsample': 0.13589948304816402}</td>\n      <td>{'datetime': '2020-10-30 12:14:41', 'elapsed': 0.0, 'delta': 0.0}</td>\n      <td>xgboost</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.49</td>\n      <td>{'ccp_alpha': 0.093135940132959, 'max_depth': 62.35607029188777, 'min_samples_split': 70.7404728288455, 'n_estimators': 35.040512564710355}</td>\n      <td>{'datetime': '2020-10-30 12:15:31', 'elapsed': 0.163065, 'delta': 0.163065}</td>\n      <td>forest</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.49</td>\n      <td>{'ccp_alpha': 0.032360585782017004, 'max_depth': 37.335790596710524, 'min_samples_split': 83.22619687861788, 'n_estimators': 282.22859485163144}</td>\n      <td>{'datetime': '2020-10-30 12:15:34', 'elapsed': 2.910612, 'delta': 0.891473}</td>\n      <td>forest</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.49</td>\n      <td>{'ccp_alpha': 0.023023364312866, 'max_depth': 67.5729089671003, 'min_samples_split': 64.6490529306644, 'n_estimators': 170.31280438723786}</td>\n      <td>{'datetime': '2020-10-30 12:15:32', 'elapsed': 1.195543, 'delta': 0.613753}</td>\n      <td>forest</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": [
       "    target  \\\n",
       "0     0.99   \n",
       "14    0.99   \n",
       "4     0.99   \n",
       "6     0.99   \n",
       "10    0.99   \n",
       "11    0.99   \n",
       "12    0.99   \n",
       "13    0.99   \n",
       "27    0.89   \n",
       "9     0.89   \n",
       "28    0.88   \n",
       "22    0.87   \n",
       "20    0.87   \n",
       "17    0.87   \n",
       "29    0.87   \n",
       "19    0.85   \n",
       "21    0.85   \n",
       "23    0.85   \n",
       "24    0.85   \n",
       "26    0.84   \n",
       "16    0.82   \n",
       "18    0.82   \n",
       "25    0.57   \n",
       "8     0.51   \n",
       "7     0.51   \n",
       "2     0.51   \n",
       "15    0.50   \n",
       "1     0.49   \n",
       "5     0.49   \n",
       "3     0.49   \n",
       "\n",
       "                                                                                                                                                                                                              params  \\\n",
       "0                                                                        {'ccp_alpha': 0.029834902375002, 'max_depth': 35.69860577029296, 'min_samples_split': 4.497178477874517, 'n_estimators': 406.4077438886299}   \n",
       "14                                                                      {'ccp_alpha': 0.049457167892975, 'max_depth': 21.34714460344915, 'min_samples_split': 2.097431305959691, 'n_estimators': 489.86987505735203}   \n",
       "4                                                                    {'ccp_alpha': 0.021861492413113002, 'max_depth': 83.05304497803968, 'min_samples_split': 20.243912858025652, 'n_estimators': 270.7014108189465}   \n",
       "6                                                                     {'ccp_alpha': 0.043781538376893005, 'max_depth': 62.67572775871829, 'min_samples_split': 46.88187614036777, 'n_estimators': 358.8362393777668}   \n",
       "10                                                                                                 {'ccp_alpha': 0.01, 'max_depth': 44.14258634567429, 'min_samples_split': 2.0, 'n_estimators': 360.63113095974927}   \n",
       "11                                                                                                {'ccp_alpha': 0.1, 'max_depth': 105.0, 'min_samples_split': 25.40894051245977, 'n_estimators': 158.47752924077685}   \n",
       "12                                                                                     {'ccp_alpha': 0.069757657642516, 'max_depth': 75.70271526835617, 'min_samples_split': 2.0, 'n_estimators': 389.6688850547288}   \n",
       "13                                                                                                              {'ccp_alpha': 0.1, 'max_depth': 105.0, 'min_samples_split': 2.0, 'n_estimators': 247.90684002652753}   \n",
       "27    {'gamma': 5.7300257335118445, 'learning_rate': 0.22360059477888103, 'max_depth': 3.8748947524170463, 'min_child_weight': 0.341132165498487, 'n_estimators': 86.43925887285536, 'subsample': 0.499383142077564}   \n",
       "9                                                                       {'ccp_alpha': 0.090029399554787, 'max_depth': 89.50191040914383, 'min_samples_split': 54.93897219851763, 'n_estimators': 160.88551700701495}   \n",
       "28      {'gamma': 21.120544444663825, 'learning_rate': 0.22791705648514501, 'max_depth': 4.042679275107872, 'min_child_weight': 0.295275762314321, 'n_estimators': 58.5552736817226, 'subsample': 0.314009255628853}   \n",
       "22    {'gamma': 16.44338760251217, 'learning_rate': 0.05256451789020201, 'max_depth': 10.204316877141467, 'min_child_weight': 0.37087034414053205, 'n_estimators': 46.822120065426, 'subsample': 0.9300408535358081}   \n",
       "20   {'gamma': 5.438404255901645, 'learning_rate': 0.09912926135240001, 'max_depth': 10.875423657001221, 'min_child_weight': 0.29817664781213604, 'n_estimators': 16.20797044801588, 'subsample': 0.427833352953212}   \n",
       "17     {'gamma': 23.902685646619545, 'learning_rate': 0.140220199304396, 'max_depth': 10.427755231286966, 'min_child_weight': 0.190043303481046, 'n_estimators': 78.53806058006883, 'subsample': 0.9309827198629641}   \n",
       "29      {'gamma': 8.242909356404795, 'learning_rate': 0.16402715204211002, 'max_depth': 4.102014314175854, 'min_child_weight': 0.254792568787706, 'n_estimators': 81.02980474091669, 'subsample': 0.582389761305676}   \n",
       "19      {'gamma': 12.065206351393131, 'learning_rate': 0.237563668878209, 'max_depth': 10.40085688904697, 'min_child_weight': 0.45836193440548206, 'n_estimators': 64.7779454870973, 'subsample': 0.690572316508353}   \n",
       "21     {'gamma': 26.845075131722044, 'learning_rate': 0.05637995945751, 'max_depth': 5.2311147200267865, 'min_child_weight': 0.38931716803493505, 'n_estimators': 99.60686866353187, 'subsample': 0.668658337550876}   \n",
       "23    {'gamma': 29.098063156312993, 'learning_rate': 0.132438457038936, 'max_depth': 6.760558963353372, 'min_child_weight': 0.20321910481126101, 'n_estimators': 89.52767108203464, 'subsample': 0.9907861999654861}   \n",
       "24  {'gamma': 35.40752339424799, 'learning_rate': 0.11638576576879502, 'max_depth': 11.946226616391376, 'min_child_weight': 0.21271170406467202, 'n_estimators': 22.473116195253535, 'subsample': 0.941746701654088}   \n",
       "26      {'gamma': 12.008139725538545, 'learning_rate': 0.190519070111762, 'max_depth': 10.277996345197241, 'min_child_weight': 0.10229010266377, 'n_estimators': 64.2924671568606, 'subsample': 0.32337358470530403}   \n",
       "16     {'gamma': 21.349653589083115, 'learning_rate': 0.21358292424761802, 'max_depth': 9.566140475222866, 'min_child_weight': 0.528480038845596, 'n_estimators': 94.42886299055723, 'subsample': 0.391226481412892}   \n",
       "18     {'gamma': 28.70720798082302, 'learning_rate': 0.252551849877212, 'max_depth': 6.481601351187299, 'min_child_weight': 0.5701211390530441, 'n_estimators': 86.78484184655254, 'subsample': 0.44040453871295304}   \n",
       "25   {'gamma': 38.070990054984044, 'learning_rate': 0.28076336388418605, 'max_depth': 9.327504220779613, 'min_child_weight': 0.5628833420567271, 'n_estimators': 22.270791810081622, 'subsample': 0.604910459818371}   \n",
       "8                                                                      {'ccp_alpha': 0.040246899179255, 'max_depth': 49.92967821882293, 'min_samples_split': 57.113265209214546, 'n_estimators': 420.89718548783173}   \n",
       "7                                                                   {'ccp_alpha': 0.057339702313048004, 'max_depth': 25.554099877521686, 'min_samples_split': 69.38910049608978, 'n_estimators': 241.34776350907418}   \n",
       "2                                                                    {'ccp_alpha': 0.010163693535097001, 'max_depth': 75.53338720453232, 'min_samples_split': 85.32894324650903, 'n_estimators': 106.00648636175973}   \n",
       "15    {'gamma': 18.63749998555996, 'learning_rate': 0.13918876224437302, 'max_depth': 4.452858224882912, 'min_child_weight': 0.134993520008951, 'n_estimators': 55.72801664920143, 'subsample': 0.13589948304816402}   \n",
       "1                                                                        {'ccp_alpha': 0.093135940132959, 'max_depth': 62.35607029188777, 'min_samples_split': 70.7404728288455, 'n_estimators': 35.040512564710355}   \n",
       "5                                                                   {'ccp_alpha': 0.032360585782017004, 'max_depth': 37.335790596710524, 'min_samples_split': 83.22619687861788, 'n_estimators': 282.22859485163144}   \n",
       "3                                                                         {'ccp_alpha': 0.023023364312866, 'max_depth': 67.5729089671003, 'min_samples_split': 64.6490529306644, 'n_estimators': 170.31280438723786}   \n",
       "\n",
       "                                                                                             datetime  \\\n",
       "0                                   {'datetime': '2020-10-30 12:15:31', 'elapsed': 0.0, 'delta': 0.0}   \n",
       "14                       {'datetime': '2020-10-30 12:15:45', 'elapsed': 14.030575, 'delta': 2.085842}   \n",
       "4                         {'datetime': '2020-10-30 12:15:33', 'elapsed': 2.019139, 'delta': 0.823596}   \n",
       "6                         {'datetime': '2020-10-30 12:15:35', 'elapsed': 4.171425, 'delta': 1.260813}   \n",
       "10                         {'datetime': '2020-10-30 12:15:40', 'elapsed': 8.294351, 'delta': 1.25263}   \n",
       "11                         {'datetime': '2020-10-30 12:15:40', 'elapsed': 9.178861, 'delta': 0.88451}   \n",
       "12             {'datetime': '2020-10-30 12:15:42', 'elapsed': 10.656779, 'delta': 1.4779179999999998}   \n",
       "13                       {'datetime': '2020-10-30 12:15:43', 'elapsed': 11.944733, 'delta': 1.287954}   \n",
       "27             {'datetime': '2020-10-30 12:14:42', 'elapsed': 1.201651, 'delta': 0.12539799999999998}   \n",
       "9                         {'datetime': '2020-10-30 12:15:38', 'elapsed': 7.041721, 'delta': 0.594742}   \n",
       "28                        {'datetime': '2020-10-30 12:14:43', 'elapsed': 1.287337, 'delta': 0.085686}   \n",
       "22                        {'datetime': '2020-10-30 12:14:42', 'elapsed': 0.708824, 'delta': 0.078763}   \n",
       "20            {'datetime': '2020-10-30 12:14:42', 'elapsed': 0.489853, 'delta': 0.029512999999999998}   \n",
       "17             {'datetime': '2020-10-30 12:14:41', 'elapsed': 0.269099, 'delta': 0.14562899999999998}   \n",
       "29                        {'datetime': '2020-10-30 12:14:43', 'elapsed': 1.418638, 'delta': 0.131301}   \n",
       "19                          {'datetime': '2020-10-30 12:14:42', 'elapsed': 0.46034, 'delta': 0.09467}   \n",
       "21                        {'datetime': '2020-10-30 12:14:42', 'elapsed': 0.630061, 'delta': 0.140208}   \n",
       "23                        {'datetime': '2020-10-30 12:14:42', 'elapsed': 0.866756, 'delta': 0.157932}   \n",
       "24  {'datetime': '2020-10-30 12:14:42', 'elapsed': 0.9163319999999999, 'delta': 0.049575999999999995}   \n",
       "26                        {'datetime': '2020-10-30 12:14:42', 'elapsed': 1.076253, 'delta': 0.089782}   \n",
       "16  {'datetime': '2020-10-30 12:14:41', 'elapsed': 0.12347000000000001, 'delta': 0.12347000000000001}   \n",
       "18  {'datetime': '2020-10-30 12:14:42', 'elapsed': 0.36567000000000005, 'delta': 0.09657099999999999}   \n",
       "25             {'datetime': '2020-10-30 12:14:42', 'elapsed': 0.986471, 'delta': 0.07013899999999999}   \n",
       "8                         {'datetime': '2020-10-30 12:15:38', 'elapsed': 6.446979, 'delta': 1.372838}   \n",
       "7                         {'datetime': '2020-10-30 12:15:36', 'elapsed': 5.074141, 'delta': 0.902716}   \n",
       "2               {'datetime': '2020-10-30 12:15:32', 'elapsed': 0.58179, 'delta': 0.41872499999999996}   \n",
       "15                                  {'datetime': '2020-10-30 12:14:41', 'elapsed': 0.0, 'delta': 0.0}   \n",
       "1                         {'datetime': '2020-10-30 12:15:31', 'elapsed': 0.163065, 'delta': 0.163065}   \n",
       "5                         {'datetime': '2020-10-30 12:15:34', 'elapsed': 2.910612, 'delta': 0.891473}   \n",
       "3                         {'datetime': '2020-10-30 12:15:32', 'elapsed': 1.195543, 'delta': 0.613753}   \n",
       "\n",
       "      model  \n",
       "0    forest  \n",
       "14   forest  \n",
       "4    forest  \n",
       "6    forest  \n",
       "10   forest  \n",
       "11   forest  \n",
       "12   forest  \n",
       "13   forest  \n",
       "27  xgboost  \n",
       "9    forest  \n",
       "28  xgboost  \n",
       "22  xgboost  \n",
       "20  xgboost  \n",
       "17  xgboost  \n",
       "29  xgboost  \n",
       "19  xgboost  \n",
       "21  xgboost  \n",
       "23  xgboost  \n",
       "24  xgboost  \n",
       "26  xgboost  \n",
       "16  xgboost  \n",
       "18  xgboost  \n",
       "25  xgboost  \n",
       "8    forest  \n",
       "7    forest  \n",
       "2    forest  \n",
       "15  xgboost  \n",
       "1    forest  \n",
       "5    forest  \n",
       "3    forest  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator.compile_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.029834902375002192,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 35,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 4,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 406,\n",
       " 'n_jobs': -1,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Check if the best RF model matches the best rf parameters in the above table\n",
    "a.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
