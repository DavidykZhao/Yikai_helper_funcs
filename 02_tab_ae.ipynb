{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp tab_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = pd.read_csv(path/'adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [Categorify, FillMissing, Normalize]\n",
    "y_names = 'salary'\n",
    "y_block = CategoryBlock()\n",
    "splits = RandomSplitter()(range_of(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = TabularPandas(df, procs = [Categorify, FillMissing, Normalize], cat_names=cat_names, cont_names=cont_names, \n",
    "                   splits=splits, y_names=['salary'], y_block=CategoryBlock())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = to.dataloaders(bs=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dl = TabDataLoader(to.train, bs = 1280)\n",
    "# valid_dl = TabDataLoader(to.valid, bs = 1280)\n",
    "# dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.389453</td>\n      <td>0.420394</td>\n      <td>0.779484</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.368908</td>\n      <td>0.363753</td>\n      <td>0.836763</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.359075</td>\n      <td>0.353150</td>\n      <td>0.836149</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.352354</td>\n      <td>0.353868</td>\n      <td>0.838759</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.346758</td>\n      <td>0.358574</td>\n      <td>0.834306</td>\n      <td>00:00</td>\n    </tr>\n  </tbody>\n</table>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = tabular_learner(dls, layers=[200,100], metrics=[accuracy])\n",
    "#learn.fit(5, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Transforms and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ReadTabBatchIdentity(ItemTransform):\n",
    "    \"Read a batch of data and return the inputs as both `x` and `y`\"\n",
    "    def __init__(self, to): self.to = to\n",
    "\n",
    "    def encodes(self, to):\n",
    "        if not to.with_cont: res = (tensor(to.cats).long(),) + (tensor(to.cats).long(),)\n",
    "        else: res = (tensor(to.cats).long(),tensor(to.conts).float()) + (tensor(to.cats).long(), tensor(to.conts).float())\n",
    "        if to.device is not None: res = to_device(res, to.device)\n",
    "        return res\n",
    "    \n",
    "class TabularPandasIdentity(TabularPandas): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates()\n",
    "class TabDataLoaderIdentity(TabDataLoader):\n",
    "    \"A transformed `DataLoader` for AutoEncoder problems with Tabular data\"\n",
    "    do_item = noops\n",
    "    def __init__(self, dataset, bs=16, shuffle=False, after_batch=None, num_workers=0, **kwargs):\n",
    "        if after_batch is None: after_batch = L(TransformBlock().batch_tfms)+ReadTabBatchIdentity(dataset)\n",
    "        super().__init__(dataset, bs=bs, shuffle=shuffle, after_batch=after_batch, num_workers=num_workers, **kwargs)\n",
    "\n",
    "    def create_batch(self, b): return self.dataset.iloc[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "TabularPandasIdentity._dl_type = TabDataLoaderIdentity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = TabularPandasIdentity(df, [Categorify, FillMissing, Normalize], cat_names, cont_names, splits=RandomSplitter(seed=32)(df))\n",
    "dls = to.dataloaders(bs=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.n_inp = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastcore, fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'workclass': 10,\n",
       " 'education': 17,\n",
       " 'marital-status': 8,\n",
       " 'occupation': 16,\n",
       " 'relationship': 7,\n",
       " 'race': 6,\n",
       " 'education-num_na': 3}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cats = {k:len(v) for k,v in to.classes.items()}\n",
    "total_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([v for k,v in total_cats.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 38.5793696495067,\n",
       " 'fnlwgt': 190006.02011593536,\n",
       " 'education-num': 10.079158508963875}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to.means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = pd.DataFrame.from_dict({k:[v] for k,v in to.means.items()})\n",
    "stds = pd.DataFrame.from_dict({k:[v] for k,v in to.stds.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = (df[cont_names].min().to_frame().T.values - means.values) / stds.values\n",
    "high = (df[cont_names].max().to_frame().T.values - means.values) / stds.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class RecreatedLoss(Module):\n",
    "    \"Measures how well we have created the original tabular inputs\"\n",
    "    def __init__(self, cat_dict):\n",
    "        ce = CrossEntropyLossFlat(reduction='sum')\n",
    "        mse = MSELossFlat(reduction='sum')\n",
    "        #store_attr('cat_dict,ce,mse')\n",
    "        self.cat_dict = cat_dict\n",
    "        self.ce = ce\n",
    "        self.mse = mse\n",
    "\n",
    "    def forward(self, preds, cat_targs, cont_targs):\n",
    "        cats, conts = preds\n",
    "        tot_ce, pos = cats.new([0]), 0\n",
    "        for i, (k,v) in enumerate(self.cat_dict.items()):\n",
    "            tot_ce += self.ce(cats[:, pos:pos+v], cat_targs[:,i])\n",
    "            pos += v\n",
    "        \n",
    "        norm_cats = cats.new([len(self.cat_dict)])\n",
    "        norm_conts = conts.new([conts.size(1)])\n",
    "        cat_loss = tot_ce/norm_cats\n",
    "        cont_loss = self.mse(conts, cont_targs)/norm_conts\n",
    "        total = cat_loss+cont_loss\n",
    "\n",
    "        return total / cats.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = RecreatedLoss(total_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BatchSwapNoise(Module):\n",
    "    \"Swap Noise Module\"\n",
    "    def __init__(self, p): self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            mask = torch.rand(x.size()) > (1 - self.p)\n",
    "            l1 = torch.floor(torch.rand(x.size()) * x.size(0)).type(torch.LongTensor)\n",
    "            l2 = (mask.type(torch.LongTensor) * x.size(1))\n",
    "            res = (l1 * l2).view(-1)\n",
    "            idx = torch.arange(x.nelement()) + res\n",
    "            idx[idx>=x.nelement()] = idx[idx>=x.nelement()]-x.nelement()\n",
    "            return x.flatten()[idx].view(x.size())\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TabularAE(TabularModel):\n",
    "    \"A simple AutoEncoder model\"\n",
    "    def __init__(self, emb_szs, n_cont, hidden_size, cats, low, high, ps=0.2, embed_p=0.01, bswap=None):\n",
    "        super().__init__(emb_szs, n_cont, layers=[1024, 512, 256], out_sz=hidden_size, embed_p=embed_p)\n",
    "        \n",
    "        self.bswap = bswap\n",
    "        self.cats = cats\n",
    "        self.activation_cats = sum([v for k,v in cats.items()])\n",
    "        \n",
    "        self.layers = nn.Sequential(*L(self.layers.children())[:-1] + nn.Sequential(LinBnDrop(256, hidden_size, p=ps, act=Mish())))\n",
    "        \n",
    "        if(bswap != None): self.noise = BatchSwapNoise(bswap)\n",
    "        self.decoder = nn.Sequential(\n",
    "            LinBnDrop(hidden_size, 256, p=ps, act=Mish()),\n",
    "            LinBnDrop(256, 512, p=ps, act=Mish()),\n",
    "            LinBnDrop(512, 1024, p=ps, act=Mish())\n",
    "        )\n",
    "        \n",
    "        self.decoder_cont = nn.Sequential(\n",
    "            LinBnDrop(1024, n_cont, p=ps, bn=False, act=None),\n",
    "            SigmoidRange(low=low, high=high)\n",
    "        )\n",
    "        \n",
    "        self.decoder_cat = LinBnDrop(1024, self.activation_cats, p=ps, bn=False, act=None)\n",
    "        \n",
    "    def forward(self, x_cat, x_cont=None, encode=False):\n",
    "        if(self.bswap != None):\n",
    "            x_cat = self.noise(x_cat)\n",
    "            x_cont = self.noise(x_cont)\n",
    "        encoded = super().forward(x_cat, x_cont)\n",
    "        if encode: return encoded # return the representation\n",
    "        decoded_trunk = self.decoder(encoded)\n",
    "        decoded_cats = self.decoder_cat(decoded_trunk)\n",
    "        decoded_conts = self.decoder_cont(decoded_trunk)\n",
    "        return decoded_cats, decoded_conts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>10.602939</td>\n      <td>9.226448</td>\n      <td>00:07</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>5.434954</td>\n      <td>1.711648</td>\n      <td>00:06</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.295231</td>\n      <td>1.030882</td>\n      <td>00:07</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.273335</td>\n      <td>0.725697</td>\n      <td>00:07</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.731029</td>\n      <td>0.694927</td>\n      <td>00:07</td>\n    </tr>\n  </tbody>\n</table>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "loss_func = RecreatedLoss(total_cats)\n",
    "emb_szs = get_emb_sz(to.train)\n",
    "\n",
    "model = TabularAE(emb_szs, len(cont_names), 128, ps=0.1, cats=total_cats, embed_p=0.01,\n",
    "              bswap=.1, low=tensor(low), high=tensor(high))\n",
    "learn = Learner(dls, model, loss_func=loss_func, wd=0.01, opt_func=ranger)\n",
    "\n",
    "learn.fit_one_cycle(n_epoch = 5, lr_max = 1e-3, wd=0.1,  cbs=[EarlyStoppingCallback(min_delta=0.05, patience = 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "dc31fd7c26e2425bbd851b0f8cbbcd5639dbbd39b944c75542f3e50c42eb2a32"
    }
   },
   "name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
